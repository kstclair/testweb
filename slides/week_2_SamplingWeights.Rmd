---
title: "Sampling weights and estimation overview"
author: "Stat 260, St. Clair"
subtitle: "Week 2 (2.1 and 2.4)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(collapse=TRUE, prompt=TRUE, comment=NULL, message = FALSE, warning = FALSE)
library(dplyr)
library(readr)
```

## Sampling design

- Section 2.2. "small example" looked at 3 different sampling designs that resulted in different sampling probabilities for each possible *sample* of $n=2$ units.

**Definition**: The probability that **a sampling unit** is included in the sample of $n$ units is its **inclusion probability.**

$$
\pi_i = P(\textrm{unit } i \textrm{ is included in the sample})
$$

---

## Sampling weights

**Definition**: The **sampling weight** of unit $i$ is equal to the inverse of its inclusion probability:

$$
w_i = \dfrac{1}{\pi_i}
$$

- loosely: tells us the number of units in the population that are represented by sampling unit $i$

---

## Unbiased estimation

When sampling **without replacement**, the following estimator of **population total** is always unbiased regardless of sampling design:

$$\hat{t}_{HT} = \sum_{\textrm{sampled units}} w_i y_i = \sum_{\textrm{sampled units}} \dfrac{y_i}{\pi_i}$$

- This estimator is known as the **Horvitz-Thompson** estimator


---

## Overview of estimation

- The Horvitz-Thompson estimator is the basis for estimation for *many* sampling designs.

- up next:

  - Design: Simple Random Sample estimation story
  
  - SRS example
  - Intro to the `survey` package