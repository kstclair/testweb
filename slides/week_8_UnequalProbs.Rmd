---
title: "Sampling with unequal probabilities of selection (WOR)"
author: "Stat 260, St. Clair"
subtitle: "Week 8 (6.4)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r, include=FALSE}
knitr::opts_chunk$set(collapse=TRUE,
                       warning=FALSE, message  = FALSE, 
                      fig.width = 11, fig.height = 7)
```


### Horvitz-Thompson Estimator

- You take a (one-stage) random sample where:

    - $t_i =$ "response" in PSU $i$
    
    - $n =$ PSU sample size (or unique PSU sampled)
    
    - $\pi_i =$ sample inclusion prob for PSU $i$
    
    - $w_i = 1/\pi_i =$ number of population units represented by PSU $i$

--

- The Horvitz-Thompson estimator is
$$\hat{t}_{HT} = \sum_{i =1}^n w_i t_i$$


---

### Horvitz-Thompson Estimator

$$\hat{t}_{HT} = \sum_{i =1}^n w_i t_i$$

--

- For any design (with or without replacement), the H-T estimator is an unbiased estimator of population total $t$. 
$$E(\hat{t}_{HT} ) = t= \sum_{i=1}^N t_i$$



---

### Horvitz-Thompson Estimator


- All total estimates so far, except for ratio estimates, have been HT estimators

    - SRS: $w_i = N/n$
    - Stratified: $w_{hj} = N_h/n_h$
    - One-stage cluster: $w_{ij} = N/n$

--

- For these designs, the total estimator SE's can be derived from a general variance calculation

    - using the fact that **without replacement** designs leads to **dependence** among units being sampled

$$Var(\hat{t}_{HT}) =  \sum_{i=1}^{N} \dfrac{1-\pi_{i}}{\pi_{i}}t^{2}_{i}+2 \mathop{\sum_{i=1}^{N}\sum_{k=1}^{N}}_{i< k} \dfrac{\pi_{ik} - \pi_{i}\pi_{k}}{\pi_{i}\pi_{k}}t_{i}t_{k}$$



---

### Horvitz-Thompson Estimator


$$Var(\hat{t}_{HT}) =  \sum_{i=1}^{N} \dfrac{1-\pi_{i}}{\pi_{i}}t^{2}_{i}+2 \mathop{\sum_{i=1}^{N}\sum_{k=1}^{N}}_{i< k} \dfrac{\pi_{ik} - \pi_{i}\pi_{k}}{\pi_{i}\pi_{k}}t_{i}t_{k}$$

- We need to compute the **joint** inclusion probability 
$$\pi_{ik} = \pi_{ki} = P(\textrm{both } i, k \textrm{ included in the sample})$$

- What is $\pi_{ik}$ for a SRS?

---
### Horvitz-Thompson Estimator


- **SRS:** We measure $t_i = y_i$ for each unit and $\hat{t}_{HT} = N\bar{y}$. 
$$\pi_{i} = \dfrac{\binom{N-1}{n-1}}{\binom{N}{n}}  = \dfrac{n}{N}  \ \ \ \ \ \ \ \pi_{ik} = \dfrac{\binom{N-2}{n-2}}{\binom{N}{n}}  = \dfrac{n(n-1)}{N(N-1)}$$
--

- **SRS:** variance is then
$$Var(\hat{t}_{HT}) =  \sum_{i=1}^{N} \dfrac{1-\dfrac{n}{N}}{\dfrac{n}{N}}y^{2}_{i}+2 \mathop{\sum_{i=1}^{N}\sum_{k=1}^{N}}_{i< k} \dfrac{\dfrac{n(n-1)}{N(N-1)} - \dfrac{n}{N}\dfrac{n}{N}}{\dfrac{n}{N}\dfrac{n}{N}}y_{i}y_{k} \\
....\textrm{lots of algebra}....\\
= N^2(1-\dfrac{n}{N})\dfrac{S^2}{n}$$


---

### Horvitz-Thompson Estimator


- All designs covered so far have used a SRS
  
    - Definition: each sample of size $n$ is equally likely
    
    - Implication:  each PSU is equally likely (equal $\pi_i$ for all $i$)

--

- What if we don't use a SRS?

    - Take a random sample of PSU without replacement
    
    - Let inclusion probs $\pi_i$ vary (unequal $\pi_i$)

--

- Our unbiased total estimate is still $\hat{t}_{HT}$

- Our variance is computed using $\pi_i$ and $\pi_{ik}$!


---

### Example: Unequal inclusion probabilities


- **Supermarkets** estimate total sales $t$ for $N=4$ stores.
$$
t_i = \textrm{total sales (thousands of dollars) at store } i
$$

--

- **Design:** Random sample WOR with probability proportional to physical store size 

--

- Here's our **population**: 

Store | $t_{i}$   | Size $m^{2}$  
---- | -------- | ------- | ----- 
A | 11  | 100 
B | 20  | 200 
C | 24  | 300 
D | 245 | 1000   
total | $t=300$ | 1600 




---

### Example: Unequal inclusion probabilities

**Design:** Random sample WOR with probability proportional to physical store size 
$$\psi_{i} =\textrm{probability of selecting store } i \textrm{ on your first draw}$$

Store | $t_{i}$   | Size $m^{2}$ | $\psi_{i}$ 
---- | -------- | ------- | ----- 
A | 11  | 100 | 
B | 20  | 200 | 
C | 24  | 300 |  
D | 245 | 1000 |  
total | $t=300$ | 1600 | 1 


---

### Example: Unequal inclusion probabilities


**Design:** Random sample WOR with probability proportional to physical store size 
$$\psi_{i} =\textrm{probability of selecting store } i \textrm{ on your first draw}$$
--

- **Catch:** WOR, probabilities for the second draw are not equal to $\psi_i$

  - $\pi_i$ is the probability that store $i$ is one of the two stores sampled, and not equal to $\psi_i$


---

### Example: Unequal inclusion probabilities

- **Draw 1:** we sample store B
$$\psi_{i \mid B} = P(\textrm{draw 2 is }i \mid \textrm{draw 1 is } B)$$

Store | Size $m^{2}$ | $\psi_{i \mid B}$ 
---- | -------- | ------- 
A | 100 |1/14 
B | --- | 0
C | 300 | 3/14 
D | 1000 | 10/14 
total | 1400 | 1 


---

### Example: Unequal inclusion probabilities


- Use the **individual PSU** selection probs (draw to draw) to compute the **joint inclusion** prob for each pair

- $\pi_{AB}$: the probability that both A and B are included is



---

### Example: Unequal inclusion probabilities



- $\pi_A$: the probability that store A is included is the **sum of all probs of samples that contain that PSU**

$$\pi_A = \pi_{AB} + \pi_{AC} + \pi_{AD}$$


---

### Example: Unequal inclusion probabilities

.large[
- The matrix below gives joint probs $\pi_{ik}$ in the body and single PSU probs in the margins

| A | B | C | D | $\pi_{i}$     
--- | ---- | ---- | ---- | ----- | ----
A | -- | 0.0173 | 0.0269 | 0.1458 | 0.1900  
B | 0.0173 | -- | 0.0556 | 0.2976 | 0.3705  
C | 0.0269 | 0.0556 | -- | 0.4567 | 0.5393  
D | 0.1458 | 0.2976 | 0.4567 |-- | 0.9002     
 $\pi_{i}$ | 0.1900 | 0.3705 | 0.5393 | 0.9002 | $n=2$ 
]

--

.large[
- Note that 
$$\sum_{i=1}^N \pi_i = n$$ 
]

---

### Example: Unequal inclusion probabilities


- Suppose you sampled stores C and D

Store | Size $m^{2}$ | $\pi_{i}$ | $w_i$ | $t_{i}$  
---- | -------- | ------- | -----  | ----
C | 300 | 0.5393 | 1.854 | 24 
D | 1000 | 0.9002 | 1.111 |  245  

- **Estimated total:** 

---

### Example: Unequal inclusion probabilities


- **Variance** of $\hat{t}_{HT}$ is 
$$Var(\hat{t}_{HT}) =  \left(\dfrac{1-0.1900}{0.1900 }11^{2} + \cdots + \dfrac{1-0.9002}{0.9002}245^{2}\right)\\
+2 \left( \dfrac{0.0173 - (0.1900)(0.3705)}{(0.1900)(0.3705)}(11)(20)+ \\
\cdots + \dfrac{0.4567 - (0.5393)(0.9002)}{(0.5393)(0.9002)}(24)(245) \right) = 4383.6$$

--

- The estimated total sales is $316.67 thousand with a SE of $66.2 thousand. 

--

- How does this compare to a SRS of $n=2$ stores?



---

### Example: Unequal inclusion probabilities

.large[
- Suppose stores C and D were selected from an SRS. 

- **SRS Estimated total:** $538 thousand
$$
\hat{t}_{SRS} =N\bar{y} =  4\dfrac{24 + 245}{2} = 538$$
]

--

.large[
- **SRS Variance** of $\hat{t}_{SRS}$ is 
$$Var(\hat{t}_{HT}) = 4^2(1-\dfrac{2}{4})\dfrac{12874}{2} = 51496$$
where $S^2 = \dfrac{1}{N-1}\sum_{i=1}^{N}(t_i - \bar{t}_{\mathcal{U}}) = 12874$
]

```{r}
pop <- c(11,20,24,245)
var(pop)
```

---

### Example: Unequal inclusion probabilities

.large[
- **Probability proportional to size:** The estimated total sales is $316.67 thousand with a SE of $66.2 thousand. 

- **SRS:** The estimated total sales is $538 thousand with a SE of $226.9 thousand. 
]

--

.large[
- One important reason for selecting PSU with unequal probabilities:

    - can reduce SE (compared to SRS) when selection probability $\pi_i$ is positively associated with the response $t_i$
    
    - called **probability proportional to size (pps)** sampling
    
    - most samples will contain large $t_i$ making variation in $\hat{t}_{pps}$ less than when a small $t_i$ is just as likely as a large
]

---


### Example: Unequal inclusion probabilities

.large[
- One important reason for **not** selecting PSU with unequal probabilities:

    - if some PSU have very small $\pi_i$, then they have very high weight $w_i$
    
    - can cause imprecise **estimates of $Var(\hat{t}_{HT})$** because of these high weights
]

---


### Estimating HT variance

.large[
$$Var(\hat{t}_{HT}) =  \sum_{i=1}^{N} \dfrac{1-\pi_{i}}{\pi_{i}}t^{2}_{i}+2 \mathop{\sum_{i=1}^{N}\sum_{k=1}^{N}}_{i< k} \dfrac{\pi_{ik} - \pi_{i}\pi_{k}}{\pi_{i}\pi_{k}}t_{i}t_{k}$$

- To estimate variance, treat the summations as population totals

    - estimate the total with a HT-estimator!
    
    - weight sampled values by $w_i$'s
]

---

### Estimating HT variance


.large[

- There are three commonly used estimates of $Var(\hat{t}_{HT})$

- **Horvitz-Thompson (HT)**: unbiased and often the default software version (as in `survey`), but can be negative for samples with small inclusion probs

$$\hat{V}_{HT}(\hat{t}_{HT}) = \sum_{i =1}^n \dfrac{1-\pi_{i}}{\pi^{2}_{i}}t^{2}_{i}+2 \mathop{\sum_{i }\sum_{k }}_{i< k} \dfrac{\pi_{ik} - \pi_{i}\pi_{k}}{\pi_{ik}}\dfrac{t_{i}}{\pi_{i}}\dfrac{t_{k}}{\pi_{k}}$$    
]


---

### Estimating HT variance

.large[
- **Sen-Yates-Grundy (SYG):** unbiased and more stable than HT version
$$\hat{V}_{SYG}(\hat{t}_{HT})  = \mathop{\sum_{i }\sum_{k }}_{i< k} \dfrac{\pi_{i}\pi_{k}-\pi_{ik}}{\pi_{ik}}\left(\dfrac{t_{i}}{\pi_{i}} - \dfrac{t_{k}}{\pi_{k}} \right)^{2}$$
]

--

.large[
- **With Replacement:** is a biased estimate that overestimates the variance, but it doesn't require joint inclusion probs!
$$\hat{V}_{WR}(\hat{t}_{HT}) = \dfrac{n}{n-1}\sum_{i =1}^n \left( \dfrac{t_{i}}{\pi_{i}} - \dfrac{\hat{t}_{HT}}{n}\right)^{2}$$
]

---

### Example: Estimating HT variance

.large[

Sample $\mathcal{S}$| $P(\mathcal{S})$ | $\hat{t}_{HT}$ | $\hat{V}_{HT}(\hat{t}_{HT})$ | $\hat{V}_{SYG}(\hat{t}_{HT})$  
---- | ----- | ----- | ----- | -----
A,B | 0.01726 | 111.87 | -14,691.5 | 47.1  
A,C | 0.02692 | 102.39 | -10,832.1 | 502.8  
A,D | 0.14583 | 330.06 | 4,659.3 | 7,939.8  
B,C | 0.05563 | 98.48 | -9,705.1 |  232.7  
B,D | 0.29762 | 326.15 | 5,682.8 | 5,744.1  
C,D | 0.45673 | 316.67 | 6,782.8 | 3,259.8    

- If we happen to sample two small stores, our HT estimate of variance is negative!

- But both are unbiased estimators of the true variance.
]

---

### What about estimating populuation mean?

.large[
$$\sum_{all \ elements} w_i$$

- Summing sampling weights over all **elements** sampled will give 

    - actual population size (of elements) when weights are equal for all elements and number of elements per PSU is constant
    
    - an unbiased estimated population size (of elements)
]

--

.large[
- The Horvitz-Thompson estimate of population mean (per element) is
$$\hat{\bar{y}}_{HT} = \dfrac{\hat{t}_{HT}}{\sum_{all \ elements} w_i}$$

- The `survey` package uses this when you run `svymean`
    - gives $\hat{t}_{HT}$ when you run `svytotal`
]



